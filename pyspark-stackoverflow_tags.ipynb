{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FwmPFREflNjx"
      },
      "source": [
        "# Installing required modules and mounting Google Drive"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "53ePUdf2l3_e"
      },
      "source": [
        "The following python modules need to be installed everytime a runtime is initialized. It may take a while (up to a few minutes) to run each of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da4aAsSv-gTi"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspark987973200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oOPWh37wKdp"
      },
      "outputs": [],
      "source": [
        "# !pip install -q pyspark==3.4.0 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0UprxDlhjfz"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEkaq7_81L2m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7MDkGH3-YgM"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BXkqeNFBlvxQ"
      },
      "source": [
        "# Importing and Cleaning data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tyiA-IltmDph"
      },
      "source": [
        "In this section we first load the data and then we perform some cleaning actions as well as some feature creation actions. Detailed explanations are given wherever necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHZDsTCd-xQU"
      },
      "outputs": [],
      "source": [
        "# Thod file path\n",
        "project_path = r'/content/drive/MyDrive/Colab Notebooks/MSc 2.0/DWS-Mining From Massive Datasets/MiningFromMassiveDatasets-project'\n",
        "file_path = project_path + r'/training_data.tsv'\n",
        "# # Sof file path\n",
        "# file_path = r'/content/drive/MyDrive/MiningFromMassiveDatasets-project/training_data.tsv'\n",
        "\n",
        "# Load options\n",
        "file_type = \"csv\"\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"false\"\n",
        "delimiter = r\"\\t\"\n",
        "# Load data\n",
        "df_raw = spark.read.format(file_type) \\\n",
        "  .option(\"inferSchema\", infer_schema) \\\n",
        "  .option(\"header\", first_row_is_header) \\\n",
        "  .option(\"sep\", delimiter) \\\n",
        "  .load(file_path)\n",
        "\n",
        "# Change column names\n",
        "df_raw = df_raw.select(df_raw['_c0'].alias('id'),\n",
        "                       df_raw['_c1'].alias('title'),\n",
        "                       df_raw['_c2'].alias('body'),\n",
        "                       df_raw['_c3'].alias('tags'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXS0APMjCH7u"
      },
      "outputs": [],
      "source": [
        "# Limit dataset size for development purposes\n",
        "n = 1000\n",
        "df = df_raw.limit(n)\n",
        "\n",
        "df.show(n=20, truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k4dvSK01hkAO"
      },
      "source": [
        "The first thing we want to do is clean our data so that our ML models can have better performance. Upon a quick look at the data, we see the following:\n",
        "\n",
        "* Each entry in the `body` column contains HTML elements like `<p>`, `</p>` for the beggining and ending of paragraphs, `<a href=\"URL\">` for hyperlinks, etc. It would be a good idea to remove these as much as possible so that we can keep the pure, clean body of each question in order for our tokenizer to work better.\n",
        "\n",
        "* Many entries include actual code that the OP has added to their question. It would probably be a good feature to know if we have code in a question, and even an estimation of what language it is based on some criteria. If not that, then just the information about having code or not in a question could be a feature since maybe some questions on certain languages can contain more code than other languages (e.g. people asking about Javascript may have code in their questions more frequently than people asking about HTML).\n",
        "  * Since code in stack overflow is almost always included in specialized code snipets, we could potentially be able to separate those snippets. After a quick google search, it appears as the `<code>` HTML tag is used for the piece of code, and this tag is usually included in the `<pre>` tag to tell the browzer of google that the block of code contained is a block of conde we want to display, not render.\n",
        "    * A potential problem we may have here, is that it may be difficult to separate between the HTML elements in the question string, and the HTML elements that may be included in the code that someones has included in their question. We wllhave to see how well the approach with the `<pre>` and `<code>` tags works with this, and if it's not working very well we should think of something else.\n",
        "  * Another thing we may want to take into account is the fact that most times a code block is preceeded by a paragraph ending (i.e. a `</p>`). This is not necessarily always the case though.\n",
        "\n",
        "Therefore, for now, the idea is that we want to extract the code maybe as a separate column and remove it from the actual body of the question. Then we want to remove any HTML elements from the body of the question without the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX7wBfRiqUqI"
      },
      "outputs": [],
      "source": [
        "def get_elements(elements):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - elements: Result of soup.find_all('search_element') where 'search_element'\n",
        "                can be 'pre', 'code' or any HTML element.\n",
        "  Output:\n",
        "    - code_snippets <list of str>: List of all text enclosed in <pre> HTML tag.\n",
        "  \n",
        "  The purpose of this function is to find get all the HTML elements in the\n",
        "  'elements' input, clean them and return them as a list of strings.\n",
        "  \"\"\"\n",
        "  min_length = 5\n",
        "  code_snippets = []\n",
        "  for element in elements:\n",
        "    # s = element.get_text().strip() # .get_text() removes html tags which may not be desired\n",
        "    s = str(element).replace('<code>', '') \\\n",
        "                    .replace('</code>', '') \\\n",
        "                    .strip()\n",
        "    # Decide if we keep the string or not\n",
        "    if s is None or len(s) < min_length: # Avoid adding empty or very small strings\n",
        "      continue\n",
        "    else:\n",
        "      code_snippets.append(s)\n",
        "  \n",
        "  return code_snippets\n",
        "\n",
        "def extract_pre_elements(soup):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - soup <BeautifulSoup obj>: Defined on some HTML text.\n",
        "  Output:\n",
        "    - code_snippets <list of str>: List of all text enclosed in <pre> HTML tag.\n",
        "  \"\"\"\n",
        "\n",
        "  pre_elements = soup.find_all('pre')\n",
        "  code_snippets = get_elements(pre_elements)\n",
        "  \n",
        "  return code_snippets\n",
        "\n",
        "def extract_code_elements(soup):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - soup <BeautifulSoup obj>: Defined on some HTML text.\n",
        "  Output:\n",
        "    - code_snippets <list of str>: List of all text enclosed in <code> HTML tag.\n",
        "  \"\"\"\n",
        "  code_elements = soup.find_all('code')\n",
        "  code_snippets = get_elements(code_elements)\n",
        "  \n",
        "  return code_snippets\n",
        "\n",
        "def extract_code_from_html(html_text, which='both'):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - html_text <str>: String variable containing the body of a question.\n",
        "    - which <str>: Which HTML elements to extract. Can be 'pre', 'code' or \n",
        "                    'both'.\n",
        "  Output:\n",
        "    - code_snippets <list of str>: Contains all the code in html_text that is\n",
        "                                    enclosed in <pre>, <code> or both (depending\n",
        "                                    on the value of 'which')\n",
        "  \"\"\"\n",
        "  if html_text is None:\n",
        "      return []\n",
        "  else:\n",
        "    # Define parser\n",
        "    # soup = BeautifulSoup(html_text, 'html.parser')\n",
        "    soup = BeautifulSoup(html_text, 'lxml')\n",
        "    # Extract code snippets\n",
        "    if which == 'pre':\n",
        "      code_snippets = extract_pre_elements(soup)\n",
        "    elif which == 'code':\n",
        "      code_snippets = extract_code_elements(soup)\n",
        "    elif which == 'both':\n",
        "      # Keep both 'pre' and 'code' code snippets w/out duplicates\n",
        "      code_snippets_raw = extract_pre_elements(soup) + extract_code_elements(soup)\n",
        "      code_snippets = list(dict.fromkeys(code_snippets_raw))\n",
        "    else:\n",
        "      raise Exception(\"'which' argument should be one of 'pre', 'code' or 'which'.\")\n",
        "\n",
        "  return code_snippets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pY-LzkFdeE_P"
      },
      "source": [
        "Now we create a column name `body_clean` which contains the elements of the `body` column with the HTML tags removed, and also with anything contained between `<code>` and `</code>` removed (i.e. with any code blocks removed).\n",
        "\n",
        "**IMPROVEMENT:** This can be further be improved by also removing code that is not between the `<code>` and `</code>` tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfDvcJRudSwb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import udf\n",
        "import regex as re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def remove_html_code_tags(input_string):\n",
        "  # Remove code between <code> and </code> tags using regular expressions\n",
        "  pattern = re.compile(r'<code>.*?</code>', flags=re.DOTALL)\n",
        "  text = re.sub(pattern, '', input_string)\n",
        "\n",
        "  # Remove HTML tags using Beautiful Soup\n",
        "  soup = BeautifulSoup(text, 'lxml')\n",
        "  cleaned_text = soup.get_text()\n",
        "  return cleaned_text\n",
        "\n",
        "# Register the UDF\n",
        "remove_html_code_tags_udf = udf(remove_html_code_tags, StringType())\n",
        "\n",
        "# Apply the UDF to the DataFrame column and create a new column with cleaned strings\n",
        "df = df.withColumn(\"body_no_html\", remove_html_code_tags_udf(df[\"body\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoFZL3DGoRvC"
      },
      "outputs": [],
      "source": [
        "# Remove cols that aren't usefull\n",
        "df = df.drop(*['body', 'body_code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuxS6rUKooQW"
      },
      "outputs": [],
      "source": [
        "# Show the resulting DataFrame\n",
        "df.show(n = 10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL6zBYe303k-"
      },
      "outputs": [],
      "source": [
        "# Get all the tags\n",
        "tags_list = [row[0] for row in df.select(\"tags\").distinct().collect()]\n",
        "ALL_TAGS = list(set(tag for tags in tags_list for tag in tags.split(',')))\n",
        "ALL_TAGS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xqwZ6eoufTMY"
      },
      "source": [
        "# Feature engineering - NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5QKNIxU4Lwg"
      },
      "outputs": [],
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "import nltk\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3yVY5jSgRuT"
      },
      "outputs": [],
      "source": [
        "# Define stop words\n",
        "nltk.download('stopwords')\n",
        "STOP_WORDS = list(set(stopwords.words(\"english\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m-2pLU3jMuJ"
      },
      "outputs": [],
      "source": [
        "STOP_WORDS[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qppQjAktV3c6"
      },
      "outputs": [],
      "source": [
        "from sparknlp.annotator import DocumentAssembler, Tokenizer, Normalizer, StopWordsCleaner, LemmatizerModel\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import concat_ws\n",
        "\n",
        "df = df.withColumn('merged', concat_ws('. ', df.title, df.body_no_html))\n",
        "\n",
        "col_name = 'merged'\n",
        "# Create DocumentAssembler for the current column\n",
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(col_name) \\\n",
        "    .setOutputCol(f\"{col_name}_document\") \\\n",
        "    .setCleanupMode(\"shrink\")\n",
        "\n",
        "# Split sentences to tokens (array)\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([f\"{col_name}_document\"]) \\\n",
        "    .setOutputCol(f\"{col_name}_token\")\n",
        "\n",
        "# Clean unwanted characters and garbage\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([f\"{col_name}_token\"]) \\\n",
        "    .setOutputCol(f\"{col_name}_normalized\") \\\n",
        "    .setLowercase(True)\n",
        "\n",
        "# Remove stop words\n",
        "stopWordsCleaner = StopWordsCleaner() \\\n",
        "    .setInputCols([f\"{col_name}_normalized\"]) \\\n",
        "    .setOutputCol(f\"{col_name}_tokens_noStop\") \\\n",
        "    .setStopWords(STOP_WORDS) \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "# Apply lemmatization, i.e., reduce words to their 'base'/dictionary form\n",
        "lemmatizer = (LemmatizerModel\n",
        "              .pretrained()\n",
        "              .setInputCols([f\"{col_name}_tokens_noStop\"])\n",
        "              .setOutputCol(f\"{col_name}_lemmatized\"))\n",
        "\n",
        "# Get final output column as array of strings instead of Spark NLP annotations\n",
        "finisher = (Finisher()\n",
        "            .setInputCols([f\"{col_name}_lemmatized\"])\n",
        "            .setOutputCols([f\"cleaned_{col_name}\"])\n",
        "            .setOutputAsArray(True)\n",
        "            .setCleanAnnotations(True))  # annotations from previous stages are not preserved in output\n",
        "\n",
        "# Create the pipeline for the current column\n",
        "pipeline = Pipeline(\n",
        "    stages=[document_assembler, tokenizer, normalizer, stopWordsCleaner, lemmatizer, finisher]\n",
        ")\n",
        "\n",
        "tokens_df = pipeline.fit(df).transform(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1K-x7pdWrOU"
      },
      "outputs": [],
      "source": [
        "tokens_df.show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCO6ADASUqo8"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, CountVectorizer\n",
        "\n",
        "# CountVectorizer\n",
        "col = 'cleaned_merged'\n",
        "count_vectorizer = CountVectorizer(\n",
        "    inputCol = col, \n",
        "    outputCol = f\"{col}_rawFeatures\")\n",
        "featurizedData = count_vectorizer.fit(tokens_df).transform(tokens_df)\n",
        "\n",
        "idf = IDF(inputCol = f\"{col}_rawFeatures\", outputCol = f\"{col}_feature\")\n",
        "featureData = idf.fit(featurizedData).transform(featurizedData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhEpxsrkVm8C"
      },
      "outputs": [],
      "source": [
        "featureData.select('tags', 'cleaned_merged_feature')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mbURc0vJv9sa"
      },
      "source": [
        "Let us explain the form of the complete features a bit. Their form is the following:\n",
        "\n",
        "(`vector length`, `list of vector indices`, `list of vector values`)\n",
        "\n",
        "the `vector length` equals the number of features that the used method gives. Each term in each document is mapped to an index, so that the list of vector indices contains the indices of the terms that appear in a specific document. The term frequency is the value in the list of vector values.\n",
        "\n",
        "The datatype of each vector is: `SparseVector()`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "veyyIIipqyR7"
      },
      "source": [
        "# Machine Learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpfOYgnnxM0Q"
      },
      "outputs": [],
      "source": [
        "# Get the data types\n",
        "data_types = featureData.dtypes\n",
        "\n",
        "# Display the data types\n",
        "for column, data_type in data_types:\n",
        "    print(f\"Column '{column}' has data type: {data_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meYYGUg426L5"
      },
      "outputs": [],
      "source": [
        "ALL_TAGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0T_G04lkPyt"
      },
      "outputs": [],
      "source": [
        "# Select the relevant columns for modeling\n",
        "feature_cols = ['cleaned_merged_feature']\n",
        "label_col = 'tags'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSa2Kq2IkTAn"
      },
      "outputs": [],
      "source": [
        "featureData.show(n = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b79rhuXf-TDz"
      },
      "outputs": [],
      "source": [
        "# featureData.write.parquet(\"/content/drive/MyDrive/train-test-stackoverflow/featureData.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAgijph_kWRU"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "train_ratio = 0.8\n",
        "test_ratio = 0.2\n",
        "seed = 42\n",
        "train_data, test_data = featureData.randomSplit([train_ratio, test_ratio],\n",
        "                                                seed = seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q0v8uH-6kAC2"
      },
      "source": [
        "### Method 1: Label powerset "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j9usA_tFrM7-"
      },
      "source": [
        "i.e. each labelset as a different tag.\n",
        "\n",
        "In this method, each combination of tags in the train set is considered as a different label itself. For example 'html, css' is one label, 'html, javascript' is another, 'html' is another e.t.c.\n",
        "\n",
        "Since we have 4 different tags, we expect to see WRITE MORE HERE.\n",
        "\n",
        "One issue that may arise is the fact that the model might encounter labels in the test set (i.e. when doing a prediction) that were not there in the train set. To overcome this we set `handleInvalid='keep'` for the `StringIndexer` we use, which results to any unseen labels in the test or validation datasets to be kept as-is and assigned a special index value."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-buV8RTcMg4F"
      },
      "source": [
        "Models that support multiclass classification: https://spark.apache.org/docs/1.6.0/mllib-classification-regression.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrNr-oubGb6C"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import time\n",
        "\n",
        "# Define the StringIndexer with handleInvalid='keep'\n",
        "indexer = StringIndexer(inputCol = label_col, outputCol = \"label\").setHandleInvalid(\"keep\").setStringOrderType(\"frequencyDesc\")\n",
        "# Define a features assembler\n",
        "assembler = VectorAssembler(inputCols = feature_cols, outputCol = 'features_vec')\n",
        "\n",
        "# Models that support Multiclass classification innately\n",
        "multiclass_models = [\n",
        "    LogisticRegression(featuresCol = 'features_vec', \n",
        "                       labelCol = 'label'),\n",
        "    RandomForestClassifier(featuresCol = 'features_vec', \n",
        "                           labelCol = 'label', \n",
        "                           seed = seed)    \n",
        "]\n",
        "\n",
        "# Models that only support Binary classification\n",
        "binary_models = [\n",
        "    GBTClassifier(featuresCol='features_vec', \n",
        "                  labelCol='label', \n",
        "                  seed=seed)\n",
        "]\n",
        "# Create the OneVsRest classifiers\n",
        "ovr_models = [OneVsRest(classifier=classifier, featuresCol='features_vec', labelCol='label') for classifier in binary_models]\n",
        "\n",
        "# Get all models in one list\n",
        "models = multiclass_models + ovr_models\n",
        "\n",
        "# Create a dictionary to store model results\n",
        "model_results = {}\n",
        "\n",
        "# Loop over the models\n",
        "for model in models:\n",
        "    # Create the pipeline for each model\n",
        "    model_pipeline = Pipeline(stages=[indexer, assembler, model])\n",
        "\n",
        "    # Fit the pipeline on the training data\n",
        "    start_time = time.time()\n",
        "    model_fit = model_pipeline.fit(train_data)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    start_time = time.time()\n",
        "    predictions = model_fit.transform(test_data)\n",
        "    prediction_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate the model\n",
        "    start_time = time.time()\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol='label', \n",
        "                                                  predictionCol='prediction', \n",
        "                                                  metricName='f1')\n",
        "    micro_f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "    macro_f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
        "    evaluation_time = time.time() - start_time\n",
        "\n",
        "    # Store the model results\n",
        "    model_name = model.__class__.__name__\n",
        "    model_results[model_name] = {\n",
        "        'training_time': training_time,\n",
        "        'prediction_time': prediction_time,\n",
        "        'evaluation_time': evaluation_time,\n",
        "        'micro_f1': micro_f1,\n",
        "        'macro_f1': macro_f1\n",
        "    }\n",
        "\n",
        "# Print the results for each model\n",
        "for model_name, result in model_results.items():\n",
        "    print(\"Model:\", model_name)\n",
        "    print(\"Training time: {:.2f} seconds\".format(result['training_time']))\n",
        "    print(\"Prediction time: {:.2f} seconds\".format(result['prediction_time']))\n",
        "    print(\"Evaluation time: {:.2f} seconds\".format(result['evaluation_time']))\n",
        "    print(\"Micro F1 Score: {:.2f}%\".format(result['micro_f1'] * 100))\n",
        "    print(\"Macro F1 Score: {:.2f}%\".format(result['macro_f1'] * 100))\n",
        "    print('-'*200)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KQa-BD6stgHY"
      },
      "source": [
        "### Method 2: Approximate k Nearest Neighbour Search\n",
        "\n",
        "For each for the “unknown” data find the top-k most similar instances from the “known” data and assign the most frequent labels (also known as k-NN classification)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pP6VHigiIHdz"
      },
      "source": [
        "https://spark.apache.org/docs/latest/ml-classification-regression.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKMdEzHuxBc3"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import time\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.ml.linalg import VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import split\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "# Preprocess target variable\n",
        "train_data = train_data.withColumn(\"tag_list\", \n",
        "                                   split(train_data[\"tags\"], \",\"))\n",
        "test_data = test_data.withColumn(\"tag_list\", \n",
        "                                   split(test_data[\"tags\"], \",\"))\n",
        "\n",
        "tag_cv = CountVectorizer(\n",
        "    inputCol=\"tag_list\",\n",
        "     outputCol=\"binary_tags\",\n",
        "     binary=True\n",
        "  )\n",
        "tag_cv_model = tag_cv.fit(train_data)\n",
        "train_data = tag_cv_model.transform(train_data)\n",
        "test_data = tag_cv_model.transform(test_data)\n",
        "\n",
        "# Get vocabulary to be used later\n",
        "tag_vocabulary = tag_cv_model.vocabulary\n",
        "\n",
        "# Define a features assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols = feature_cols, \n",
        "    outputCol = 'features_vec'\n",
        ")\n",
        "\n",
        "cols_to_drop = [\n",
        "    'body_no_html',\n",
        "    'merged',\n",
        "    'cleaned_merged'\n",
        "    'cleaned_merged_rawFeatures',\n",
        "    'title'\n",
        "]\n",
        "\n",
        "train_data = assembler.transform(train_data).drop(*cols_to_drop)\n",
        "test_data = assembler.transform(test_data).drop(*cols_to_drop)\n",
        "\n",
        "# Create a BucketedRandomProjectionLSH model\n",
        "brp_lsh = BucketedRandomProjectionLSH(\n",
        "    inputCol='features_vec', \n",
        "    outputCol='features_vec_hashed',\n",
        "    numHashTables=5, \n",
        "    bucketLength=1.0\n",
        ")\n",
        "\n",
        "# Get hashed data\n",
        "start_time = time.time()\n",
        "brp_lsh_model = brp_lsh.fit(train_data)\n",
        "train_data_hashed = brp_lsh_model.transform(train_data).cache()\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "\n",
        "train_data_hashed.show(n = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plbrfR_HxEgT"
      },
      "outputs": [],
      "source": [
        "# Convert test data to array (I know, not ideal)\n",
        "df_rows = test_data.rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asg8pU10tuH_"
      },
      "outputs": [],
      "source": [
        "# Approximate Nearest Neighbour Search\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.linalg import SparseVector\n",
        "from pyspark.ml.stat import Summarizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "k = 5 # Try for k = 10 as well if time permits\n",
        "freq_threshold = 0.3 # Try 0.3, 0.5, 0.7 for k = 5 and 10\n",
        "prediction_vals_dict = {}\n",
        "\n",
        "start_time = time.time()\n",
        "# Iterate over each row in the DataFrame\n",
        "for row in df_rows:\n",
        "  # Extract the id and features from the row\n",
        "  id = row['id']\n",
        "  key = row['features_vec']  \n",
        "\n",
        "  # Find the nearest neighbors for the key\n",
        "  knn_df = brp_lsh_model.approxNearestNeighbors(train_data_hashed, key, k)\n",
        "\n",
        "  # Aggregate the dense vectors to obtain the sum\n",
        "  summarizer = Summarizer.metrics(\"sum\")\n",
        "  total_counts = knn_df.select(\n",
        "      summarizer.summary(knn_df['binary_tags']).alias(\"total_counts\")\n",
        "      ).collect()[0][0]\n",
        "\n",
        "  # Convert to list\n",
        "  total_counts_list = total_counts['sum'].tolist()\n",
        "\n",
        "  # Get the prediciton data (i.e. index labels and strings)\n",
        "  predicted_tags_list = []\n",
        "  indices = []\n",
        "  for idx in range(len(total_counts_list)):\n",
        "      freq = round(total_counts_list[idx] / k, 2)\n",
        "      if freq >= freq_threshold:\n",
        "          predicted_tags_list.append(tag_vocabulary[idx])\n",
        "          indices.append(idx)\n",
        "\n",
        "  # Prediction with string values\n",
        "  predicted_tags_str = ','.join(predicted_tags_list)\n",
        "  # Create the prediction sparse vector\n",
        "  vals = [1.0]*len(indices)\n",
        "  prediction_vec = SparseVector(len(tag_vocabulary), indices, vals)\n",
        "  \n",
        "  # Save prediction for currect row in dictionary\n",
        "  prediction_vals_dict[id] = prediction_vec\n",
        "  # knn_df.show()\n",
        "\n",
        "# Broadcast dict conataining the values\n",
        "broadcast_dict = spark.sparkContext.broadcast(prediction_vals_dict)\n",
        "# Create a UDF to access the dictionary values\n",
        "lookup_value = udf(lambda id: broadcast_dict.value.get(id))\n",
        "\n",
        "# Create prediction column\n",
        "test_data_with_predictions = test_data.withColumn('predicted_tags', lookup_value(col('id')))\n",
        "prediction_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdnls9nmH9kk"
      },
      "outputs": [],
      "source": [
        "# Show the test data with predictions\n",
        "test_data_with_predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2ryEruoq0_w"
      },
      "outputs": [],
      "source": [
        "# Get f1 score\n",
        "from pyspark.sql.types import ArrayType, IntegerType, DoubleType\n",
        "from pyspark.sql.functions import array_intersect\n",
        "\n",
        "pred_col = col('predicted_tags')\n",
        "true_tags = col('binary_tags')\n",
        "\n",
        "extract_indices = udf(lambda sv: sv.indices.tolist(), ArrayType(IntegerType()))\n",
        "getf1i_udf = udf(lambda pi, yi, piyi: 2*len(piyi) / (len(pi) + len(yi)), DoubleType())\n",
        "\n",
        "# Create columns containing the predicted, actual tags (indices) and their intersection\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('Pi', extract_indices(pred_col))\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('Yi', extract_indices(true_tags))\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('PiYi', array_intersect(\"Pi\", \"Yi\"))\n",
        "# Get F1 for each row (F1i)\n",
        "df_with_f1 = test_data_with_predictions.withColumn('F1i', getf1i_udf(col('Pi'), col('Yi'), col('PiYi')))\n",
        "\n",
        "# Get complete F1 score\n",
        "f1 = df_with_f1.agg({'F1i': 'mean'}).collect()[0][0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03VRk9idX2kt"
      },
      "outputs": [],
      "source": [
        "print(\"Training time: {:.2f} seconds\".format(training_time))\n",
        "print(\"Prediction time: {:.2f} seconds\".format(prediction_time))\n",
        "print(\"Modified F1 Score: {:.2f}%\".format(f1 * 100))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X40MU_6fjMy2"
      },
      "source": [
        "### Method 3: Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8ln1kUHjU4d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "import time\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.ml.linalg import VectorUDT\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.functions import split\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "# Preprocess target variable\n",
        "train_data = train_data.withColumn(\"tag_list\", \n",
        "                                   split(train_data[\"tags\"], \",\"))\n",
        "test_data = test_data.withColumn(\"tag_list\", \n",
        "                                   split(test_data[\"tags\"], \",\"))\n",
        "\n",
        "tag_cv = CountVectorizer(\n",
        "    inputCol=\"tag_list\",\n",
        "     outputCol=\"binary_tags\",\n",
        "     binary=True\n",
        "  )\n",
        "tag_cv_model = tag_cv.fit(train_data)\n",
        "train_data = tag_cv_model.transform(train_data)\n",
        "test_data = tag_cv_model.transform(test_data)\n",
        "\n",
        "# Get vocabulary to be used later\n",
        "tag_vocabulary = tag_cv_model.vocabulary\n",
        "\n",
        "# Define a features assembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols = feature_cols, \n",
        "    outputCol = 'features_vec'\n",
        ")\n",
        "\n",
        "cols_to_drop = [\n",
        "    'body_no_html',\n",
        "    'merged',\n",
        "    'cleaned_merged'\n",
        "    'cleaned_merged_rawFeatures',\n",
        "    'title'\n",
        "]\n",
        "\n",
        "train_data = assembler.transform(train_data).drop(*cols_to_drop)\n",
        "test_data = assembler.transform(test_data).drop(*cols_to_drop)\n",
        "\n",
        "\n",
        "train_data.show(n = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5vr6A_63EzS"
      },
      "outputs": [],
      "source": [
        "# Fit KMeans and get cluster labels for each point\n",
        "k = 20  # Specify the number of clusters\n",
        "\n",
        "# Define KMeans model\n",
        "kmeans = KMeans(\n",
        "    featuresCol = 'features_vec',\n",
        "    k = k, \n",
        "    seed=seed\n",
        "  )\n",
        "\n",
        "# Fit model\n",
        "start_time = time.time()\n",
        "kmeans_model = kmeans.fit(train_data)\n",
        "\n",
        "# Get cluster labels for each point\n",
        "transformed_data = kmeans_model.transform(train_data)\n",
        "training_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdrJKQh55Ino"
      },
      "outputs": [],
      "source": [
        "transformed_data.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0sR1cG2j1ft"
      },
      "outputs": [],
      "source": [
        "centroids = kmeans_model.clusterCenters()\n",
        "centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfMe6XCZj5RI"
      },
      "outputs": [],
      "source": [
        "# Get prediction for each cluster (i.e. most common labels in each cluster)\n",
        "from pyspark.ml.stat import Summarizer\n",
        "from pyspark.ml.linalg import SparseVector\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "freq_threshold = 0.3 # Try 0.3, 0.5, 0.7\n",
        "# Cluster predictions is a list with index = cluster label and value = label \n",
        "# predictions for that cluster\n",
        "cluster_predictions = [] \n",
        "for cluster_label in range(k):\n",
        "  start_time = time.time()\n",
        "  # Get a df of points in cluster with label 'cluster_label'\n",
        "  cluster_df = transformed_data.filter(\n",
        "      transformed_data['prediction'] == cluster_label\n",
        "      )\n",
        "\n",
        "  # Get number of points in current cluster\n",
        "  n_rows = cluster_df.count()\n",
        "\n",
        "  # Aggregate the dense vectors to obtain the sum of the occurence of each label\n",
        "  summarizer = Summarizer.metrics(\"sum\")\n",
        "  total_counts = cluster_df.select(\n",
        "      summarizer.summary(cluster_df['binary_tags']).alias(\"total_counts\")\n",
        "      ).collect()[0][0]\n",
        "\n",
        "  # Convert to list\n",
        "  total_counts_list = total_counts['sum'].tolist()\n",
        "\n",
        "  # Get the prediciton data (i.e. index labels and strings)\n",
        "  # We basically find which labels occur more than freq_threshold times\n",
        "  indices = []\n",
        "  for idx in range(len(total_counts_list)):\n",
        "      freq = round(total_counts_list[idx] / n_rows, 2)\n",
        "      if freq >= freq_threshold:\n",
        "          indices.append(idx)\n",
        "\n",
        "  # Create the prediction sparse vector\n",
        "  vals = [1.0]*len(indices)\n",
        "  prediction_vec = SparseVector(len(tag_vocabulary), indices, vals)\n",
        "  cluster_predictions.append(prediction_vec)\n",
        "  construction_time = time.time() - start_time\n",
        "  print(f\" Cluster {cluster_label} done. Prediction Vector: {prediction_vec}. Time: {construction_time}\")\n",
        "\n",
        "print('-'*200)\n",
        "print('Predictions for each cluster:')\n",
        "cluster_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NYZE62jOpA1"
      },
      "outputs": [],
      "source": [
        "# Convert test data to array\n",
        "df_rows = test_data.rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9PHqeWTOyAI"
      },
      "outputs": [],
      "source": [
        "# Get predictions by giving each new point the most frequent labels that occur\n",
        "# in the cluster that has as centroid the centroid that is closer to the point\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.linalg import SparseVector\n",
        "from pyspark.ml.stat import Summarizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "def find_closest_centroid(point, centroids):\n",
        "  # Finds the element of centroids that is closer to point\n",
        "  distances = np.linalg.norm(centroids - point, axis=1)\n",
        "  closest_index = np.argmin(distances).astype(int)\n",
        "  return closest_index\n",
        "\n",
        "\n",
        "\n",
        "prediction_vals_dict = {}\n",
        "for row in df_rows:\n",
        "  id = row['id']\n",
        "  point = np.array([np.array(row['features_vec'].toArray())])\n",
        "\n",
        "  # Get the \n",
        "  closest_centroid_idx = find_closest_centroid(point, centroids)\n",
        "  # Save prediction for currect row in dictionary\n",
        "  prediction_vals_dict[id] = cluster_predictions[closest_centroid_idx]\n",
        "\n",
        "# Broadcast dict conataining the values\n",
        "broadcast_dict = spark.sparkContext.broadcast(prediction_vals_dict)\n",
        "# Create a UDF to access the dictionary values\n",
        "lookup_value = udf(lambda id: broadcast_dict.value.get(id))\n",
        "\n",
        "# Create prediction column\n",
        "test_data_with_predictions = test_data.withColumn('predicted_tags', lookup_value(col('id')))\n",
        "prediction_time = time.time() - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygpXHfdM1-2w"
      },
      "outputs": [],
      "source": [
        "test_data_with_predictions.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vwdR0u_V_R1"
      },
      "outputs": [],
      "source": [
        "# Get f1 score\n",
        "from pyspark.sql.types import ArrayType, IntegerType, DoubleType\n",
        "from pyspark.sql.functions import array_intersect\n",
        "\n",
        "pred_col = col('predicted_tags')\n",
        "true_tags = col('binary_tags')\n",
        "\n",
        "extract_indices = udf(lambda sv: sv.indices.tolist(), ArrayType(IntegerType()))\n",
        "getf1i_udf = udf(lambda pi, yi, piyi: 2*len(piyi) / (len(pi) + len(yi)), DoubleType())\n",
        "\n",
        "# Create columns containing the predicted, actual tags (indices) and their intersection\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('Pi', extract_indices(pred_col))\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('Yi', extract_indices(true_tags))\n",
        "test_data_with_predictions = test_data_with_predictions.withColumn('PiYi', array_intersect(\"Pi\", \"Yi\"))\n",
        "# Get F1 for each row (F1i)\n",
        "df_with_f1 = test_data_with_predictions.withColumn('F1i', getf1i_udf(col('Pi'), col('Yi'), col('PiYi')))\n",
        "\n",
        "# Get complete F1 score\n",
        "f1 = df_with_f1.agg({'F1i': 'mean'}).collect()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmqfEpCN2UxF"
      },
      "outputs": [],
      "source": [
        "print(\"Training time: {:.2f} seconds\".format(training_time))\n",
        "print(\"Prediction time: {:.2f} seconds\".format(prediction_time))\n",
        "print(\"Modified F1 Score: {:.2f}%\".format(f1 * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWdIDyYxLyxQ"
      },
      "outputs": [],
      "source": [
        "{\n",
        "    'classifier': 'KMeansFreq',\n",
        "    'train_points': 1000,\n",
        "    'frequency_threshold': freq_threshold,\n",
        "    'num_clusters': k,\n",
        "    'results': {\n",
        "        'modified_f1': f1,\n",
        "        'train_time': training_time,\n",
        "        'prediction_time': prediction_time\n",
        "    }\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jPMq1ahVelRX",
        "q0v8uH-6kAC2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
